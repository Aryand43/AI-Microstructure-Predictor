{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4840872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9638408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         w        h       p  d=p/h  f=h/w      w.1      h.1     p.1\n",
      "0  1160.51   724.09  234.81   0.32   0.62  1160.51   724.09  234.81\n",
      "1   999.46  1163.58  134.61   0.12   1.16   999.46  1163.58  134.61\n",
      "2  6220.51  1478.29     NaN   0.00   0.24  6220.51  1478.29     NaN\n",
      "3  1197.39  1429.12     NaN   0.00   1.19  1197.39  1429.12     NaN\n",
      "4   973.34   678.29  204.69   0.30   0.70   973.34   678.29  204.69\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/labels.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11069f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48 .tif images.\n"
     ]
    }
   ],
   "source": [
    "image_dir='../data/images'\n",
    "image_files=sorted([f for f in os.listdir(image_dir) if f.endswith('.tif')])\n",
    "print(f\"Found {len(image_files)} .tif images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c6f2739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processed images: 48\n",
      "Example shape: torch.Size([1, 224, 224])\n",
      "Pixel range: 0.054901961237192154 → 0.8901960849761963\n"
     ]
    }
   ],
   "source": [
    "image_tensors=[] \n",
    "for filename in image_files: \n",
    "    img_path = os.path.join(image_dir, filename) \n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) \n",
    "    img_resized = cv2.resize(img, (224,224)) \n",
    "    img_normalized = img_resized.astype(np.float32) / 255.0 \n",
    "    img_tensor = torch.from_numpy(img_normalized).unsqueeze(0)\n",
    "    image_tensors.append(img_tensor)\n",
    "print(\"Total processed images:\", len(image_tensors))\n",
    "print(\"Example shape:\", image_tensors[0].shape)\n",
    "print(\"Pixel range:\", image_tensors[0].min().item(), \"→\", image_tensors[0].max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "396c6670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   d=p/h  f=h/w        w        h       p\n",
      "0   0.32   0.62  1160.51   724.09  234.81\n",
      "1   0.12   1.16   999.46  1163.58  134.61\n",
      "2   0.00   0.24  6220.51  1478.29     NaN\n",
      "3   0.00   1.19  1197.39  1429.12     NaN\n",
      "4   0.30   0.70   973.34   678.29  204.69\n"
     ]
    }
   ],
   "source": [
    "labels_path = '../data/labels.csv'\n",
    "df = pd.read_csv(labels_path)\n",
    "df = df[['d=p/h', 'f=h/w', 'w', 'h', 'p']]\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0fe6520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labels: 48\n",
      "Example label: tensor([3.2000e-01, 6.2000e-01, 1.1605e+03, 7.2409e+02, 2.3481e+02])\n",
      "Shape: torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "label_tensors = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i].values.astype(np.float32)\n",
    "    label_tensor = torch.tensor(row)\n",
    "    label_tensors.append(label_tensor)\n",
    "print(\"Total labels:\", len(label_tensors))\n",
    "print(\"Example label:\", label_tensors[0])\n",
    "print(\"Shape:\", label_tensors[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1cc73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from dataset import MicrostructureDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daaf8bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images batch shape: torch.Size([8, 1, 224, 224])\n",
      "Labels batch shape: torch.Size([8, 5])\n"
     ]
    }
   ],
   "source": [
    "dataset = MicrostructureDataset(\n",
    "    image_dir='../data/images',\n",
    "    label_csv='../data/labels.csv'\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "for batch in dataloader:\n",
    "    images, labels = batch\n",
    "    print(\"Images batch shape:\", images.shape)\n",
    "    print(\"Labels batch shape:\", labels.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad50d7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018dd2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([8, 5])\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from model import MicrostructureCNN\n",
    "dummy_input = torch.randn(8, 1, 224, 224)  # Simulate batch of 8 grayscale images\n",
    "model = MicrostructureCNN() \n",
    "output = model(dummy_input)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
